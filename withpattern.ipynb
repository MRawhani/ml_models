{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b8a8d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated!\n",
      "Blink sequence: [3, 2]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Please note that the shape_predictor_68_face_landmarks.dat file, which contains the pretrained model \n",
    "for detecting the facial landmarks, is not included in the dlib library\n",
    ", and you will have to download it separately. \n",
    "You can find it here: http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "\n",
    "Unzip it and provide the correct path in the script.\n",
    "'''\n",
    "\n",
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def get_ear(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Indices of left and right eyes in dlib's facial landmarks\n",
    "LEFT_EYE_INDICES = list(range(36, 42))\n",
    "RIGHT_EYE_INDICES = list(range(42, 48))\n",
    "\n",
    "EAR_THRESHOLD = 0.28  # Eye Aspect Ratio threshold for blink detection\n",
    "PAUSE_TIME_THRESHOLD = 2.0  # Pause time threshold (in seconds)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"../large_files/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "blink_count = 0\n",
    "blink_count_sequence = []\n",
    "prev_blink_detected = False\n",
    "blink_start_time = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    for rect in rects:\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        left_eye = shape[LEFT_EYE_INDICES]\n",
    "        right_eye = shape[RIGHT_EYE_INDICES]\n",
    "        left_ear = get_ear(left_eye)\n",
    "        right_ear = get_ear(right_eye)\n",
    "        avg_ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "        cv2.putText(frame, f\"EAR: {avg_ear:.2f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"Blinks: {blink_count}\", (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        blink_detected = avg_ear < EAR_THRESHOLD\n",
    "\n",
    "        if blink_detected and not prev_blink_detected:  # Blink start\n",
    "            blink_start_time = time.time()\n",
    "\n",
    "        if not blink_detected and prev_blink_detected:  # Blink end\n",
    "            blink_end_time = time.time()\n",
    "            blink_duration = blink_end_time - blink_start_time\n",
    "\n",
    "            if blink_duration >= PAUSE_TIME_THRESHOLD:\n",
    "                blink_count_sequence.append(blink_count)\n",
    "                blink_count = 0\n",
    "            else:\n",
    "                blink_count += 1\n",
    "\n",
    "        prev_blink_detected = blink_detected\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Append remaining blink count to sequence\n",
    "if blink_count > 0:\n",
    "    blink_count_sequence.append(blink_count)\n",
    "AUTHENTICATION_PATTERN = [3, 2]  # Pattern of consecutive blinks for authentication\n",
    "# Check if blink sequence matches authentication pattern\n",
    "if blink_count_sequence == AUTHENTICATION_PATTERN:\n",
    "    print(\"Authenticated!\")\n",
    "print(\"Blink sequence:\", blink_count_sequence)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb431b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6eec34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61dea3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40f1d0c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     34\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m---> 35\u001b[0m rects \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rect \u001b[38;5;129;01min\u001b[39;00m rects:\n\u001b[0;32m     38\u001b[0m     shape \u001b[38;5;241m=\u001b[39m predictor(gray, rect)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def get_ear(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "# Indices of left and right eyes in dlib's facial landmarks\n",
    "LEFT_EYE_INDICES = list(range(36, 42))\n",
    "RIGHT_EYE_INDICES = list(range(42, 48))\n",
    "\n",
    "EAR_THRESHOLD = 0.236  # Eye Aspect Ratio threshold for blink detection\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "left_blink_count = 0\n",
    "right_blink_count = 0\n",
    "prev_left_blink_detected = False\n",
    "prev_right_blink_detected = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    for rect in rects:\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        left_eye = shape[LEFT_EYE_INDICES]\n",
    "        right_eye = shape[RIGHT_EYE_INDICES]\n",
    "        left_ear = get_ear(left_eye)\n",
    "        right_ear = get_ear(right_eye)\n",
    "\n",
    "        left_blink_detected = left_ear < EAR_THRESHOLD\n",
    "        right_blink_detected = right_ear < EAR_THRESHOLD\n",
    "\n",
    "        if left_blink_detected and not prev_left_blink_detected:  # Left eye blink start\n",
    "            left_blink_count += 1\n",
    "        if right_blink_detected and not prev_right_blink_detected:  # Right eye blink start\n",
    "            right_blink_count += 1\n",
    "\n",
    "        prev_left_blink_detected = left_blink_detected\n",
    "        prev_right_blink_detected = right_blink_detected\n",
    "\n",
    "        cv2.putText(frame, f\"Left Blinks: {left_blink_count}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"Right Blinks: {right_blink_count}\", (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a26b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71019d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3982cc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45b1292e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blink sequence: [14, 2, 6, 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "import time\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "def get_ear(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return int((p1.x + p2.x)/2), int((p1.y + p2.y)/2)\n",
    "\n",
    "# Indices of left and right eyes in dlib's facial landmarks\n",
    "LEFT_EYE_INDICES = list(range(36, 42))\n",
    "RIGHT_EYE_INDICES = list(range(42, 48))\n",
    "\n",
    "EAR_THRESHOLD = 0.2  # Eye Aspect Ratio threshold for blink detection\n",
    "PAUSE_TIME_THRESHOLD = 2.0  # Pause time threshold (in seconds)\n",
    "EYE_MOVEMENT_THRESHOLD = 8.5  # Threshold for detecting rapid eye movement\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "blink_count = 0\n",
    "blink_count_sequence = []\n",
    "prev_blink_detected = False\n",
    "blink_start_time = None\n",
    "prev_eye_position = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    for rect in rects:\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        left_eye = shape[LEFT_EYE_INDICES]\n",
    "        right_eye = shape[RIGHT_EYE_INDICES]\n",
    "        left_ear = get_ear(left_eye)\n",
    "        right_ear = get_ear(right_eye)\n",
    "        avg_ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "        # Calculate the vertical position of the eyes\n",
    "        eye_position = (left_eye[3, 1] + right_eye[3, 1]) / 2.0\n",
    "\n",
    "        cv2.putText(frame, f\"EAR: {avg_ear:.2f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, f\"Blinks: {blink_count}\", (10, 60),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        \n",
    "        blink_detected = avg_ear < EAR_THRESHOLD\n",
    "\n",
    "        if prev_eye_position is not None and abs(eye_position - prev_eye_position) > EYE_MOVEMENT_THRESHOLD:\n",
    "            blink_detected = False  # Disregard the blink if the eye position has changed too much\n",
    "\n",
    "        if blink_detected and not prev_blink_detected:  # Blink start\n",
    "            blink_start_time = time.time()\n",
    "\n",
    "        if not blink_detected and prev_blink_detected:  # Blink end\n",
    "            blink_end_time = time.time()\n",
    "            blink_duration = blink_end_time - blink_start_time\n",
    "\n",
    "            if blink_duration >= PAUSE_TIME_THRESHOLD:\n",
    "                blink_count_sequence.append(blink_count)\n",
    "                blink_count = 0\n",
    "            blink_count += 1\n",
    "\n",
    "        prev_blink_detected = blink_detected\n",
    "        prev_eye_position = eye_position\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "print(\"Blink sequence:\", blink_count_sequence)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26fff86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
