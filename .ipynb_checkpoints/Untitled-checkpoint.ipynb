{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d223edb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (689129296.py, line 68)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 68\u001b[1;36m\u001b[0m\n\u001b[1;33m    if cv2.waitKey(1) & 0xFF == ord('q'):\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Blink detection related functions\n",
    "def get_ear(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    ear = (A + B) / (2.0 * C)\n",
    "    return ear\n",
    "\n",
    "LEFT_EYE_INDICES = list(range(36, 42))\n",
    "RIGHT_EYE_INDICES = list(range(42, 48))\n",
    "\n",
    "EAR_THRESHOLD = 0.28  # Eye Aspect Ratio threshold for blink detection\n",
    "PAUSE_TIME_THRESHOLD = 2.0  # Pause time threshold (in seconds)\n",
    "\n",
    "blink_count = 0\n",
    "blink_count_sequence = []\n",
    "prev_blink_detected = False\n",
    "blink_start_time = None\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Loop for each frame in the video\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    for rect in rects:\n",
    "        # Face recognition\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "        left_eye = shape[LEFT_EYE_INDICES]\n",
    "        right_eye = shape[RIGHT_EYE_INDICES]\n",
    "        left_ear = get_ear(left_eye)\n",
    "        right_ear = get_ear(right_eye)\n",
    "        avg_ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "        # Check if the face is recognized\n",
    "        roi = frame[rect.top():rect.bottom(), rect.left():rect.right()]\n",
    "        result, y_predict = Face_Recognition(roi, model, scaler, pca, clf)\n",
    "\n",
    "        if len(result) == 0:\n",
    "            cv2.putText(frame, 'Unknown', (rect.left()-5, rect.top()-5), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        else:\n",
    "            recognized_face = ImageClass(result[0])\n",
    "            cv2.putText(frame, recognized_face, (rect.left()-5, rect.top()-5), font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "            \n",
    "            # If face recognized, proceed to blink detection\n",
    "            blink_detected = avg_ear < EAR_THRESHOLD\n",
    "\n",
    "            if blink_detected and not prev_blink_detected:\n",
    "                blink_start_time = time.time()\n",
    "            elif not blink_detected and prev_blink_detected:\n",
    "                blink_duration = time.time() - blink_start_time\n",
    "                blink_count += 1\n",
    "                blink_count_sequence.append(blink_duration)\n",
    "\n",
    "            prev_blink_detected = blink_detected\n",
    "\n",
    "        cv2.rectangle(frame, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (255, 0, 0), 2)\n",
    "\n",
    "    # Display the video\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2c8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
